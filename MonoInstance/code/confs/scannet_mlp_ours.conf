train{
    expname = scannet_mlp,
    dataset_class = datasets.scene_dataset.SceneDatasetDN,
    model_class = model.network.MonoSDFNetwork,
    loss_class = model.loss.MonoSDFLoss,
    learning_rate = 5.0e-4,
    lr_factor_for_grid = 20.0,
    sched_decay_rate = 0.1,
    checkpoint_freq = 10,
    plot_freq = 3,
    split_n_pixels = 1024,
    max_total_iters = 110000,
}
plot{
    plot_nimgs = 1,
    resolution = 500,   # todo: 600->500 for efficiency
    grid_boundary = [-1.0, 1.0],
}
loss{
    rgb_loss = torch.nn.L1Loss,
    eikonal_weight = 0.1,
    #smooth_weight = 0.005,
    #depth_weight = 0.5,
    #normal_l1_weight = 0.05,
    #normal_cos_weight = 0.05,
    warp_weight = 0.4,
    smooth_weight = 0.000,
    depth_weight = 0.7,
    normal_l1_weight = 0.05,
    normal_cos_weight = 0.05,
}
dataset{
    data_dir = scannet,
    img_res = [484, 648],
    scan_id = 1,
    num_pixels = 1024,
}
model{
    feature_vector_size = 256,
    scene_bounding_sphere = 1.1,
    img_res = [484, 648],
    Grid_MLP = True,

    implicit_network
    {
        d_in = 3,
        d_out = 1,
        dims = [256, 256, 256, 256, 256, 256, 256, 256],
        geometric_init = True,
        bias = 0.65,
        skip_in = [4],
        weight_norm = True,
        multires = 6,
        inside_outside = True,
        use_grid_feature = False,
        divide_factor = 1.1,
    }

    rendering_network
    {
        mode = idr ,
        d_in = 9 ,
        d_out = 3,
        dims = [ 256, 256],
        weight_norm = True,
        multires_view = 4,
        per_image_code = True,
    }
    density
    {
        params_init{
            beta = 0.1,
        }
        beta_min = 0.0001,
    }
    ray_sampler
    {
        near = 0.0,
        N_samples = 64 ,
        N_samples_eval = 128 ,
        N_samples_extra = 32 ,
        eps = 0.1,
        beta_iters = 10,
        max_total_iters = 5,
    }
}
